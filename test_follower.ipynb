{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/giordamaug/WisardLib4Python/blob/main/test_follower.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/giordamaug/WisardLib4Python.git\n",
    "%cd WisardLib4Python\n",
    "!pip install pybind11\n",
    "!pip install opencv_jupyter_ui\n",
    "!python setup.py build_ext --inplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n",
      "building 'wisard' extension\n",
      "creating build/temp.macosx-11.0-arm64-cpython-313\n",
      "clang++ -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /Users/maurizio/miniconda3/envs/py4julia/include -arch arm64 -fPIC -O2 -isystem /Users/maurizio/miniconda3/envs/py4julia/include -arch arm64 -I/Users/maurizio/miniconda3/envs/py4julia/lib/python3.13/site-packages/pybind11/include -I/Users/maurizio/miniconda3/envs/py4julia/lib/python3.13/site-packages/pybind11/include -I/Users/maurizio/miniconda3/envs/py4julia/include/python3.13 -c ram.cpp -o build/temp.macosx-11.0-arm64-cpython-313/ram.o -std=c++14\n",
      "clang++ -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /Users/maurizio/miniconda3/envs/py4julia/include -arch arm64 -fPIC -O2 -isystem /Users/maurizio/miniconda3/envs/py4julia/include -arch arm64 -I/Users/maurizio/miniconda3/envs/py4julia/lib/python3.13/site-packages/pybind11/include -I/Users/maurizio/miniconda3/envs/py4julia/lib/python3.13/site-packages/pybind11/include -I/Users/maurizio/miniconda3/envs/py4julia/include/python3.13 -c wisard.cpp -o build/temp.macosx-11.0-arm64-cpython-313/wisard.o -std=c++14\n",
      "creating build/lib.macosx-11.0-arm64-cpython-313\n",
      "clang++ -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /Users/maurizio/miniconda3/envs/py4julia/include -arch arm64 -fPIC -O2 -isystem /Users/maurizio/miniconda3/envs/py4julia/include -arch arm64 -bundle -undefined dynamic_lookup -Wl,-rpath,/Users/maurizio/miniconda3/envs/py4julia/lib -L/Users/maurizio/miniconda3/envs/py4julia/lib -Wl,-rpath,/Users/maurizio/miniconda3/envs/py4julia/lib -L/Users/maurizio/miniconda3/envs/py4julia/lib build/temp.macosx-11.0-arm64-cpython-313/ram.o build/temp.macosx-11.0-arm64-cpython-313/wisard.o -o build/lib.macosx-11.0-arm64-cpython-313/wisard.cpython-313-darwin.so\n",
      "copying build/lib.macosx-11.0-arm64-cpython-313/wisard.cpython-313-darwin.so -> \n"
     ]
    }
   ],
   "source": [
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opencv_jupyter_ui as jcv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import wisard as wnn\n",
    "import time\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "import os\n",
    "from functools import partial\n",
    "try:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def monitor(results):\n",
    "    zoom = 4\n",
    "    matrix_normalized = cv2.normalize(results, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    matrix_uint8 = np.uint8(matrix_normalized)\n",
    "    heatmap = cv2.applyColorMap(matrix_uint8, cv2.COLORMAP_HOT)\n",
    "    resized_heatmap = cv2.resize(heatmap, (zoom*heatmap.shape[0], zoom*heatmap.shape[1]))\n",
    "    return resized_heatmap\n",
    "\n",
    "def draw_text(img, text,\n",
    "          font=cv2.FONT_HERSHEY_PLAIN,\n",
    "          pos=(0, 0),\n",
    "          font_scale=3,\n",
    "          font_thickness=2,\n",
    "          text_color=(0, 255, 0),\n",
    "          text_color_bg=(0, 0, 0)\n",
    "          ):\n",
    "\n",
    "    x, y = pos\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.rectangle(img, pos, (x + text_w, y + text_h), text_color_bg, -1)\n",
    "    cv2.putText(img, text, (x, y + text_h + font_scale - 1), font, font_scale, text_color, font_thickness)\n",
    "    return text_size\n",
    "\n",
    "class Follower:\n",
    "     def __init__(self, frame:np.ndarray, w1:int, w2:int, h1:int, h2:int, name:int, dx:int, dy:int, res:int, color=(0,0,0), minthr=5, n_bits:int=16, map:int=0):\n",
    "        self.name = name\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.dx = dx\n",
    "        self.dy = dy\n",
    "        self.res = res\n",
    "        self.deltax = 0 \n",
    "        self.deltay = 0\n",
    "        self.color = color\n",
    "        self.width = frame.shape[1]\n",
    "        self.height = frame.shape[0]\n",
    "        self.n_bits = n_bits\n",
    "        self.map = map\n",
    "        self.minthr = minthr\n",
    "        self.w,self.h = self.w2-self.w1, self.h2-self.h1\n",
    "        self.ww1, self.hh1 = max(0, self.w1-self.dx*self.res),max(0, self.h1-self.dy*self.res)\n",
    "        self.ww2, self.hh2 = min(self.height, self.w2+self.dx*self.res),min(self.width, self.h2+self.dy*self.res)\n",
    "        if self.w1-self.dx*self.res < 0:\n",
    "            self.neww1 = self.dx*self.res - self.w1\n",
    "        else:  # left outbound\n",
    "            self.neww1 = 0\n",
    "        if self.h1-self.dy*self.res < 0:\n",
    "            self.newh1 = self.dy*self.res - self.h1\n",
    "        else:  # top outbound\n",
    "            self.newh1 = 0\n",
    "        # crop image window including dx/dy movements\n",
    "        self.crop_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)[self.ww1:self.ww2,self.hh1:self.hh2]\n",
    "        _,self.crop_img = cv2.threshold(self.crop_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "        # extend cropped image if window outbounds\n",
    "        self.crop_img_ext = np.ndarray((w2-w1+2*dx*res, h2-h1+2*dy*res), dtype=self.crop_img.dtype)\n",
    "        self.crop_img_ext.fill(255)\n",
    "        self.crop_img_ext[self.neww1:self.neww1+self.crop_img.shape[0],self.newh1:self.newh1+self.crop_img.shape[1]] = self.crop_img\n",
    "        self.crop_img_ext = np.where(self.crop_img_ext < 128, 1,0)\n",
    "\n",
    "        # cut training image from cropped (extended) window\n",
    "        self.crop_img_train = self.crop_img_ext[self.dx*self.res:self.dx*self.res+(self.w2-self.w1),self.dy*self.res:self.dy*self.res+(self.h2-self.h1)]\n",
    "        self.crop_img_train_g = (self.crop_img_train * 255).astype(\"uint8\")\n",
    "        # initi dicriminator and train on image\n",
    "        self._discr = wnn.WiSARD((self.w)*(self.h), n_bits=self.n_bits, map=self.map, classes = [name])\n",
    "        self._discr.train(self.crop_img_train.flatten(), name)\n",
    "\n",
    "     def response(self):\n",
    "        # initialize movement responses\n",
    "        result_mat = np.zeros((2 * self.dx +1, 2 * self.dy +1), dtype=float)\n",
    "        # compute tuples for predition of discriminator shifte non different windows\n",
    "        tuple_mat = self._discr._mk_tuple_img_multi(self.crop_img_ext, self.h, dx=self.dx, dy=self.dy, res=self.res)\n",
    "        thresh = max(0, self._discr.getTcounts()[self.name] - self.minthr)\n",
    "        #print(self._discr.getTcounts())\n",
    "        for i in range(2 * self.dy +1):\n",
    "            for j in range(2 * self.dx +1):\n",
    "                result_mat[j,i] = self._discr.response_tpl(tuple_mat[i,j], threshold=thresh)[self.name]\n",
    "        # get pax response and its location in response matrix\n",
    "        maxidx = np.unravel_index(np.argmax(result_mat, axis=None), result_mat.shape)\n",
    "        self.deltay, self.deltax = int((maxidx[0]-self.dy)*self.res), int((maxidx[1]-self.dx)*self.res)\n",
    "        self.maxres = result_mat[*maxidx]\n",
    "        self.monitor = monitor(result_mat)    \n",
    "\n",
    "     def update(self, frame:np.ndarray):\n",
    "        if self.deltax != 0 or self.deltay != 0:\n",
    "            #print(f\"MOVE[{self.name}]\", self.deltax,self.deltay)\n",
    "            if self.w1 + self.deltay > -1 and self.w2 + self.deltay < self.width: \n",
    "                self.w1 += self.deltay\n",
    "                self.w2 += self.deltay \n",
    "            if self.h1 + self.deltax > -1 and self.h2 + self.deltax < self.height: \n",
    "                self.h1 += self.deltax\n",
    "                self.h2 += self.deltax\n",
    "            self.w,self.h = self.w2-self.w1, self.h2-self.h1\n",
    "            self.ww1, self.hh1 = max(0, self.w1-self.dx*self.res),max(0, self.h1-self.dy*self.res)\n",
    "            self.ww2, self.hh2 = min(self.height, self.w2+self.dx*self.res),min(self.width, self.h2+self.dy*self.res)\n",
    "            if self.w1-self.dx*self.res < 0:\n",
    "                self.neww1 = self.dx*self.res - self.w1\n",
    "            else:  # left outbound\n",
    "                self.neww1 = 0\n",
    "            if self.h1-self.dy*self.res < 0:\n",
    "                self.newh1 = self.dy*self.res - self.h1\n",
    "            else:  # top outbound\n",
    "                self.newh1 = 0\n",
    "            self._discr.reinit()\n",
    "            #self._discr.untrain(self.name)  ... not working well!\n",
    "\n",
    "        # crop image window including dx/dy movements\n",
    "        self.crop_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)[self.ww1:self.ww2,self.hh1:self.hh2]\n",
    "        _,self.crop_img = cv2.threshold(self.crop_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        self.crop_img = (255-self.crop_img)\n",
    "\n",
    "        # extend cropped image if window outbounds\n",
    "        self.crop_img_ext = np.ndarray((self.w2-self.w1+2*self.dx*self.res, self.h2-self.h1+2*self.dy*self.res), dtype=self.crop_img.dtype)\n",
    "        self.crop_img_ext.fill(255)\n",
    "        self.crop_img_ext[self.neww1:self.neww1+self.crop_img.shape[0],self.newh1:self.newh1+self.crop_img.shape[1]] = self.crop_img\n",
    "        self.crop_img_ext = np.where(self.crop_img_ext < 128, 1,0)\n",
    "\n",
    "        # cut training image from cropped (extended) window\n",
    "        self.crop_img_train = self.crop_img_ext[self.dx*self.res:self.dx*self.res+(self.w2-self.w1),self.dy*self.res:self.dy*self.res+(self.h2-self.h1)]\n",
    "        self.crop_img_train_g = (self.crop_img_train * 255).astype(\"uint8\")\n",
    "        # initi dicriminator and train on image\n",
    "        self._discr.train(self.crop_img_train.flatten(), self.name)\n",
    "\n",
    "def following(filename, windows, parallel = True, output=True, debug=False):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    idxframe = 1\n",
    "    nproc = len(windows)\n",
    "    fps = 0\n",
    "    def follower_worker(d, frame):\n",
    "        d.response()\n",
    "        d.update(frame)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        raise Exception(\"No video input\")\n",
    "    frame = cv2.GaussianBlur(frame,(5,5),0)\n",
    "    window_name = f\"{os.path.splitext(os.path.basename(filename))[0]} ({frame.shape[0]}x{frame.shape[1]})\"\n",
    "    followers = [Follower(frame, *win) for win in windows]\n",
    "    if output: f = open('out.txt', 'w')\n",
    "    while(cap.isOpened()):\n",
    "        try:\n",
    "            tStart=time.time()\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                outframe = frame.copy()\n",
    "                frame = cv2.GaussianBlur(frame,(5,5),0)\n",
    "                if parallel:\n",
    "                    with Pool(processes=nproc) as pool:\n",
    "                        pool.map(partial(follower_worker, frame=frame), followers)\n",
    "                else:\n",
    "                    [follower_worker(d, frame) for d in followers]\n",
    "                for d in followers:\n",
    "                    if debug:\n",
    "                        outframe[d.w1:d.w2,d.h1:d.h2] = cv2.cvtColor(d.crop_img_train_g, cv2.COLOR_GRAY2BGR) \n",
    "                        startw = d.w2 if d.w2+d.monitor.shape[0] < frame.shape[0] else d.w1-d.monitor.shape[0]\n",
    "                        outframe[startw:startw+d.monitor.shape[0],d.h1:d.h1+d.monitor.shape[1]] = d.monitor\n",
    "                    frame = cv2.rectangle(frame, (d.h1-1,d.w1-1), (d.h2,d.w2), d.color, 2)\n",
    "                    _,_ = draw_text(frame, f\"ID:{d.name} {d.maxres:.2f}\", font_scale=1, pos=(d.h1-3,d.w1-13), text_color=(255, 255, 255), text_color_bg=d.color, font_thickness=1)\n",
    "                    \n",
    "                if output:\n",
    "                        f.write(\",\".join([f\"[ID:{d.name}]{(d.w1+d.w2)//2},{(d.h1+d.h2)//2}\" for d in followers]))\n",
    "                        f.write(\"\\n\")\n",
    "                cv2.putText(frame, f\"fps:{fps:.0f} F:{idxframe}\", (15,15), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 1)\n",
    "                if debug:\n",
    "                    jcv2.imshow(window_name,np.hstack((frame, outframe)))\n",
    "                else:\n",
    "                    jcv2.imshow(window_name,frame)\n",
    "                if jcv2.waitKey(0.1)=='q':\n",
    "                    break\n",
    "                idxframe +=1\n",
    "                fps=1.0/(time.time()-tStart)\n",
    "            else:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    if output: f.close()\n",
    "    jcv2.destroyAllWindows() #optional, only needed if you don't run it in notebook\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31419aab4ca48b9b57e28a496ea487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='danger', description='Stop', style=ButtonStyle()), HBox(children=(Label(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfac11a92388473c9215e5c62cb25f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='danger', description='Stop', style=ButtonStyle()), HBox(children=(Label(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5cb9ca02db4ec2817f1cf694d05bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center>clouds (240x360)</center>'), Canvas()), layout=Layout(border_bottom='1.5px …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exection is stopped\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# window (startx,endx,starty,endy), x is vertical axis: row index)\n",
    "windows = [(120,170,20,100, 0, 5,5,1, (255,0, 0), 5), \n",
    "           (160,214,200,290, 1, 5,5,1, (0,100, 0), 5)]\n",
    "following(\"data/clouds.mp4\", windows,\n",
    "          parallel=True, output=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4julia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
